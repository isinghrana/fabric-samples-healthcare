{"cells":[{"cell_type":"code","source":["def get_config_dict():\n","\n","    config_dict = {\n","        \"workspace_id\": notebookutils.runtime.context[\"currentWorkspaceId\"],\n","        \"lakehouse_name\": \"cms_lakehouse\"\n","    }\n","\n","    config_dict[\"lakehouse_id\"] = notebookutils.lakehouse.get(config_dict[\"lakehouse_name\"])['id']    \n","    return config_dict"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6dc1a6ec-a836-4aaf-b2fc-698bda3ad722"},{"cell_type":"code","source":["def get_full_abfss_path(workspace_id, lakehouse_id, dir):    \n","    full_abfss_path = f\"abfss://{workspace_id}@onelake.dfs.fabric.microsoft.com/{lakehouse_id}/{dir}\"\n","    return full_abfss_path\n","\n","\n","# plain pythfon code is used to write downloaded file to a non-defualt Lakehouse Files section\n","# and for that purpose \n","def mount_path_return_local_path(full_abfss_path, mount_point):\n","    notebookutils.fs.mount(full_abfss_path, mount_point)\n","    return notebookutils.fs.getMountPath(mount_point)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"94ceef8a-3c06-402a-9bcd-d219747f5ea8"},{"cell_type":"code","source":["config_dict = get_config_dict()"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"92cf123e-a111-43c8-bb88-ee31e39e3637"},{"cell_type":"code","source":["#create the sub-directory in Files folder where the CSV files will be downloaded\n","lakehouse_dir = \"Files/cmsdemofiles\"\n","lakehouse_dir_abfss_full_path = get_full_abfss_path(config_dict['workspace_id'], config_dict['lakehouse_id'], lakehouse_dir)\n","\n","notebookutils.fs.mkdirs(lakehouse_dir_abfss_full_path)\n","\n","print(f\"lakehouse_dir: {lakehouse_dir}\")\n","print(f\"lakehouse_dir_abfss_full_path: {lakehouse_dir_abfss_full_path}\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"75053d76-1a55-467e-8a59-b22b495ca23a"},{"cell_type":"code","source":["#local mount path is required for plain python to save files to Lakehouse file section\n","mount_point = \"/mnt/lakehouse/\" + config_dict[\"lakehouse_name\"] + \"/\" + lakehouse_dir\n","lakehouse_dir_local_mount_path = mount_path_return_local_path(lakehouse_dir_abfss_full_path, mount_point)\n","\n","print(f'mount point: {mount_point}')\n","print(f\"lakehouse_dir_local_path: {lakehouse_dir_local_mount_path}\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"325b9f16-5093-425c-8fee-2722feaba220"},{"cell_type":"code","source":["file_url = \"https://github.com/isinghrana/fabric-samples-healthcare/raw/refs/heads/isr-auto1/analytics-bi-directlake-starschema/demoautomation/artifacts.zip\""],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f42fbfc8-34d0-4ad5-a69b-f5a16cc183f7"},{"cell_type":"code","source":["import requests\n","\n","def download_binary_file(url, output_path):\n","    try:\n","        response = requests.get(url, stream=True)\n","        response.raise_for_status()  # Raise an error for bad status codes\n","        with open(output_path, 'wb') as file:\n","            for chunk in response.iter_content(chunk_size=8192):\n","                file.write(chunk)\n","        print(f\"File downloaded successfully to: {output_path}\")\n","    except requests.exceptions.RequestException as e:\n","        print(f\"Download failed: {e}\")\n","\n","# Example usage\n","#github_file_url = \"https://github.com/user/repo/releases/download/v1.0.0/filename.bin\"\n","#output_file_path = \"artifacts.zip\"\n","download_path = lakehouse_dir_local_mount_path + '/artifacts.zip'\n","download_binary_file(file_url, download_path)\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"09ffc9fa-fba6-47d7-9c8a-7211da191822"},{"cell_type":"code","source":["import zipfile\n","import os\n","\n","def unzip_file(zip_path, extract_to):\n","    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","        zip_ref.extractall(extract_to)\n","    print(f\"Extracted all contents to '{extract_to}'\")\n","\n","# Example usage\n","\n","unzip_file(download_path, lakehouse_dir_local_mount_path)\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"790cfec7-5ce8-4d32-a891-f26ebd61b237"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}