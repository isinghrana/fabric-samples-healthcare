{"cells":[{"cell_type":"code","source":["def get_config_dict():\n","\n","    config_dict = {\n","        \"workspace_id\": notebookutils.runtime.context[\"currentWorkspaceId\"],\n","        \"lakehouse_name\": \"cms_lakehouse\"\n","    }\n","\n","    config_dict[\"lakehouse_id\"] = notebookutils.lakehouse.get(config_dict[\"lakehouse_name\"])['id']    \n","    return config_dict"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2d334e2a-f511-4851-a702-430f591980ec"},{"cell_type":"code","source":["def get_full_abfss_path(workspace_id, lakehouse_id, dir):    \n","    full_abfss_path = f\"abfss://{workspace_id}@onelake.dfs.fabric.microsoft.com/{lakehouse_id}/{dir}\"\n","    return full_abfss_path\n","\n","\n","# plain pythfon code is used to write downloaded file to a non-defualt Lakehouse Files section\n","# and for that purpose \n","def mount_path_return_local_path(full_abfss_path, mount_point):\n","    notebookutils.fs.mount(full_abfss_path, mount_point)\n","    return notebookutils.fs.getMountPath(mount_point)\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ba361503-0a7a-4cb5-90a8-33d0cb94e082"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}