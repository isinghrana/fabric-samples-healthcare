{"cells":[{"cell_type":"markdown","source":["### 01 - Download CMS Medicare Part D data files (CSV format) to Lakehouse\n","\n","- [CMS Medicare Part D Prescribers - by Provider and Drug](https://data.cms.gov/provider-summary-by-type-of-service/medicare-part-d-prescribers/medicare-part-d-prescribers-by-provider-and-drug) dataset is available for download from CMS Website. \n","- This Notebook use [Public API Open Data Catalog](https://data.cms.gov/data.json) metadata json file published by CMS to identify and download dataset files to the Lakehouse\n","- Dataset contains one file for each year, Title field available for each in Metadata json is used tor identity the year value. Example - Title \"Medicare Part D Prescribers - by Provider and Drug : 2016-12-31\" indicates the file is for the year 2016"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e179bf6f-ce5b-4063-892d-7448ee4f6b72"},{"cell_type":"code","source":["#create the sub-directory in Files folder where the CSV files will be downloaded\n","lakehouse_dir = \"Files/cms_raw\"\n","\n","notebookutils.fs.mkdirs(lakehouse_dir)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"762a0349-842d-485b-8955-42a317e01c81"},{"cell_type":"code","source":["# Documentation provided at the following location  https://data.cms.gov/sites/default/files/2024-05/39b98adf-b5e0-4487-a19e-4dc5c1503d41/API%20Guide%20Formatted%201_5.pdf\n","# was used as basis for the following code which parses the Public API Open Data Catalog json file to identity the dataset files \n","\n","import requests\n","url = \"https://data.cms.gov/data.json\"\n","title= \"Medicare Part D Prescribers - by Provider and Drug\"\n","csv_distros =[]\n","response = requests.request(\"GET\", url)\n","\n","if response.ok:\n","    response = response.json()\n","    dataset = response['dataset']\n","    for set in dataset:\n","        if title == set['title']:\n","            for distro in set['distribution']:\n","                if 'mediaType' in distro.keys():\n","                    if distro['mediaType'] == \"text/csv\":\n","                        csv_distros.append(distro)        \n","else:\n","    error_message = f\"An error occrred in downloading the files from CMS Website: {response}\"\n","    print(error_message)\n","    notebookutils.notebook.exit(error_message, 1)\n","\n","#print(csv_distros)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2fc3ab1f-681a-469f-936b-08592e3d25f8"},{"cell_type":"code","source":["#create spark dataframe with rows for all files for the dataset\n","#downloadURL and title are the 2 fields of interest which are added as column in the dataframe\n","selected_dataset = [{\"downloadURL\": obj[\"downloadURL\"], \"title\": obj[\"title\"]} for obj in csv_distros]\n","df = spark.createDataFrame(selected_dataset)\n","display(df)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"0596f3f7-f570-490c-996c-2e474890779f"},{"cell_type":"code","source":["from pyspark.sql.functions import regexp_extract\n","\n","#identify Year value from the Title and add that as a column to dataframe\n","df = df.withColumn(\"year\", regexp_extract(\"title\", r\"(\\d{4})\", 1))\n","display(df)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"36c20ad6-1514-4170-9b50-a7ab3e944fda"},{"cell_type":"code","source":["import random, time\n","\n","\n","#function to download the file from URL\n","def download_file(url, filename, retries = 10, interval = 45):\n","\n","    attempt = 0\n","\n","    #usually APIs are rate limited so good idea to have retry pattern implemented for downloads\n","    while attempt < retries:\n","        try:\n","\n","            response = requests.get(url)    \n","            print(f\"Status Code: {response.status_code}\")  # Print the status code\n","            response.raise_for_status()  # Check if the request was successful\n","\n","            with open(filename, 'wb') as file:\n","                file.write(response.content)\n","            \n","            #file downloaded succesfully so break out of the while loop\n","            break       \n","        except requests.exceptions.RequestException as e:            \n","\n","            attempt += 1\n","            print(f\"Attempt {attempt} failed: {e}\")\n","\n","            if attempt < retries:\n","                print(f\"Retrying in {interval} seconds...\")                \n","                time.sleep(interval)\n","            else:\n","                print(\"All attempts failed. Download unsuccessful.\")\n","                raise Exception(\"Failed to download file after multiple attempts\")\n","\n","#function to process each DataFrame Row which corresponds to single file in teh dataset\n","#downloaded file is named based on the year value associated with data\n","def process_partition(partition):\n","    for row in partition:\n","        year_value = row['year']\n","        output_file = \"/lakehouse/default/\" + lakehouse_dir + \"/\" + row['year'] + \".csv\"\n","        download_file(row['downloadURL'], output_file)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"155738ee-aa7a-4aeb-8fff-9bc140ebe7eb"},{"cell_type":"code","source":["#process the dataframe where each row represents a file to be downloaded from CMS file\n","df.rdd.foreachPartition(process_partition)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"77628dc7-17a0-4061-94d1-527d91423819"}],"metadata":{"language_info":{"name":"python"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"kernel_info":{"name":"synapse_pyspark"},"widgets":{},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{},"environment":{}}},"nbformat":4,"nbformat_minor":5}